# SYSTEM DESIGN

# 初级

Q1 **描述一些常用的重新平衡数据集的方法**

- **重新平衡设计模式: **处理不平衡的数据集, 即数据集中, 其中一个标签构成了数据集的大部分, 留下的其他标签的例子要少得多
    - **缩减采样**: 减少模型训练期间使用的多数类中的示例数量.通常与集成学习结合使用以获得更好的结果.
    - **上采样**: 我们通过复制少数类示例和生成额外的合成示例来过度代表我们的少数群体.
    - **加权类**: 通过对类进行加权, 告诉我们的模型在训练期间更加重视少数标签类, 权重系数作为超参数调节
    

Q2 **知道哪些数据表示方法?**

对于数字输入: 

1. 在 $[-1,  1]$ 范围内缩放输入: 这有助于更快的收敛, 因此, 模型的训练速度更快/成本更低.有四种方法可以实现此目的: 
    - 使用最小最大缩放时, 缺点是最小值和最大值直接由训练集确定.
    - 剪切(与最小-最大缩放结合使用): 与最小最大缩放不同, 此处的最小值和最大值是合理的估计值. 此技术适用于均匀分布的数据.
    - $Z$分数归一化: 通过$ \frac{x - \mu}{\sigma} $将数据转化为无单位的$Z-Score$分值
    - 对于偏斜的数据, 我们需要在缩放之前对数据进行转换.通常使用的一些转换技术包括日志转换, 桶化输入等.
2. 当输入是数字数组时, 我们也可以用以下方法表示它: 
    - 其统计数据(如平均值, 中位数等).
    - 这是经验分布.
    - 如果数组以某种方式排序, 则数组中的固定项数.
3. 将数字输入视为分类并映射到one-hot列.这在以下情况下很有用: 
    - 当数字输入只是一个索引时, 例如, 一周中的几天.
    - 当输入和标签之间的关系不连续时, 

对于分类输入: 

1. 当输入线性独立时, 可以使用one-hot或虚拟编码.
2. 计算数组中每个项的出现次数.
3. 使用相对频率而不是计数以避免大量数字.
4. 如果数组已排序, 则由固定数量的项表示输入数组.

Q3 **描述一个机器学习系统搭建的工作流程**

- 可以按照下图中概述的步骤完成一个机器学习系统的搭建
- 抽象和隔离各个步骤的好处是可以在步骤之间插入验证, 以监控质量和状态.因此, 如果存在数据漂移或模型质量下降, 将更容易识别并更快地进行补救

![Untitled](SystemDesign/Untitled.png)

Q4 **说说你知道的模型超参数调整方法**

- **随机搜索**: 超参数创建了一个可能值的网格.每次迭代都会尝试从该网格中随机组合超参数, 记录性能, 最后返回提供最佳性能的超参数组合.
- **网格搜索: **将搜索空间定义为超参数值的网格, 并评估网格中每个位置的算法性能(遍历), 最后返回提供最佳性能的超参数组合.
- **贝叶斯优化**: 假设超参数与最后我们需要优化的损失函数存在一个函数关系, 通过SMBO等算法最小化函数, 从而得到最优的参数组合

Q5 **机器学习中使用的embedding, 有什么好处?**

- Embedding 是一个将离散变量转为连续向量表示的一个方式, Embedding 可以减少离散变量的空间维数, 同时还可以有意义的表示该变量.

![Untitled](SystemDesign/Untitled1.png)

Q6: **迁移学习的思想适合用在什么场景下?**

- 迁移学习的使用场景如下: 假设有两个任务系统A和B, 任务A拥有海量的数据资源且已经训练好, 但任务B才是我们的目标任务, 这种场景便是典型的迁移学习的应用场景. 新的任务系统和旧的任务系统必须在数据, 任务和模型等方面存在一定的相似性.

Q7: **将训练数据切分为训练集, 验证集, 测试集时, 如果不做随机化, 可能带来什么问题?**

- **如果不随机拆分, 训练和测试拆分可能最终会出现偏差**.例如, 如果您有 100 个样本, 分为两个类别, 前 80 个样本来自类别 1, 其余样本来自类别 0, 则 80/20 拆分会将所有类别 0 留在训练集中, 所有类别 1 留在测试集中.造成类别的严重不均衡

Q8: **迁移学习中, finetuning和特征提取(feature extraction)有什么区别?**

- 在微调中, 我们从预训练模型开始, 并为我们的新任务更新模型的所有参数, 本质上是重新训练整个模型, 在特征提取中, 我们从一个预训练模型开始, 只更新我们从中得出预测的最终层权重.

Q9: **在训练模型时, 早停策略可能会有什么问题?**

- 提前停止的一个问题是模型可能没有利用到所有可用的训练数据, 当数据集偏小时, 这种现象会更为明显

Q10: **如何对一个即将上线的模型进行离线和在线测试?**

- **离线评估: **衡量模型在保留样本上的表现.在数据集收集过程中, 数据被分为训练, 测试和验证子集.还可以进行 K 折交叉验证, 以找出不同数据子集下的性能.选择对所选 KPI 表现良好的模型进行实施和部署.
- **在线评价: **将训练好的模型部署到真实场景(离线评估后)的第一步是进行 A/B 测试.经过训练的模型不会很快地面对大量真实世界的数据.相反, 该模型被部署在一小部分场景中.例如, 假设设计的模型是为了匹配司机和乘客.在 A/B 测试中, 该模型将只部署在较小的地理区域而不是全部场景.然后将该模型的测试版与现有模型在更长的时间内进行比较, 如果它导致与业务相关的 KPI 性能的提高(例如  DAU/MAU, 更好的用户保留率, 并最终提高优步收入), 然后将在更大范围内实施.

Q11: **一个模型发生梯度消失时, 有什么解决方案?**

1.  **预训练加微调**
2. **使用不同的激活函数, 将sigmoid, tanh替换为relu**
3. **使用batchnorm**
4. **使用残差结构**
5. 检查是否使用了RNN, **使用LSTM网络**

# 中级

Q12: **解释AUC准则**

- AUC是ROC曲线下方区域的面积, 从所有1样本中随机选取一个样本, 从所有0样本中随机选取一个样本, 然后根据你的分类器对两个随机样本进行预测, 把1样本预测为1的概率为p1, 把0样本预测为1的概率为p2, p1>p2的概率就是AUC

![Untitled](SystemDesign/Untitled2.png)

- **另外, AUC对样本类别是否均衡并不敏感, 这也是不均衡样本通常采用AUC评价分类性能的原因**

Q13: **如何处理数据不均衡的机器学习问题?**

- 重新采样训练集, 使用欠采样和过采样
- 使用K-fold交叉验证, 使用过采样方法来解决不平衡问题时应适当地应用交叉验证
- 多模型Bagging
- 使用半监督方案, 增广少数类数据
- 调整损失函数, 加大错判少数类样本的损失

Q14: **深度学习模型训练的加速方案**

- 使用多机多卡训练: 
    - 数据并行, 即每个计算单元都保留一份完整的模型拷贝, 分别训练不同的数据, 经过一个 Iteration 或若干个 Iteration 后, 把各个计算单元的模型做一次同步
    - 模型并行, 即各个计算单元存储同一层模型数据的不同部分, 训练相同的数据
    
    ![Untitled](SystemDesign/Untitled3.png)
    
    - 流式并行, 即每个计算单元都存储不同层的模型数据, 训练相同的数据.如上图所示, GPU1 只负责第一层神经网络的计算, GPU2 只负责 2~5 层神经网络的计算, GPU3 只负责第 6 层的计算.流式并行的好处在于每个运算单元之间的通信和计算重叠(overlap), 如果配置得当, 可以非常充分地利用硬件资源
    

Q15: ****多机多卡训练时, 误差梯度如何在不同设备之间通信****

- 在每个GPU训练step结束后, 将每块GPU的损失梯度求平均

Q16: ****BN如何在不同设备之间同步****

- BN的特性是: batch_size越大, 均值和方差越接近与整个数据集的均值和方差, 效果越好.使用多块GPU时, 会计算每个BN层在所有设备上输入的均值和方差

Q17: ****DataParallel 和 DistributedDataParallel的区别****

- DataParallel是单进程多线程的, 仅仅能工作在单机多卡中.而DistributedDataParallel是多进程的, 可以工作在单机或多机器中
- DistributedDataParallel比DataParallel运行的更快, 显存分配的更加均衡

Q18: **描述单机多卡训练流程(DataParallel)**

1. 指定主机节点
2. 主机节点划分数据, 一个batch数据平均分到每个机器上
3. 模型从主机拷贝到各个机器
4. 每个机器进行前向传播
5. 每个机器计算loss损失
6. 主机收集所有loss结果, 进行参数更新
7. 将更新后参数模型拷贝给各个机器

![Untitled](SystemDesign/Untitled4.png)

Q19: **描述多机多卡的训练流程(DistributedDataParallel)**

1. 从一开始就会启动多个进程(进程数等于GPU数), 每个进程独享一个GPU, 每个进程都会独立地执行代码.这意味着每个进程都独立地初始化模型, 训练, 当然, 在每次迭代过程中会通过进程间通信共享梯度, 整合梯度, 然后独立地更新参数.
2. 每个进程都会初始化一份训练数据集, 当然它们会使用数据集中的不同记录做训练, 这相当于同样的模型喂进去不同的数据做训练, 也就是所谓的数据并行
3. 进程通过`local_rank`变量来标识自己, `local_rank`为0的为master, 其他是slave
4. 因为每个进程都会初始化一份模型, 为保证模型初始化过程中生成的随机权重相同, 需要设置随机种子.
5. 模型的保存与加载, 与单GPU的方式有所不同.这里通通将参数以cpu的方式save进存储, 因为如果是保存的GPU上参数, pth文件中会记录参数属于的GPU号, 则加载时会加载到相应的GPU上, 这样就会导致如果你GPU数目不够时会在加载模型时报错

![Untitled](SystemDesign/Untitled5.png)

引用: [https://juejin.cn/post/7082591377581670431](https://juejin.cn/post/7082591377581670431)

Q20: ****DataParallel进行单机多卡训练的优缺点****

- 代码简单: 仅需修改一行代码
- 通信瓶颈 : 负责reducer的GPU更新模型参数后分发到不同的GPU, 因此有较大的通信开销.
- GPU负载不均衡: 负责reducer的GPU需要负责汇总输出, 计算损失和更新权重, 因此显存和使用率相比其他GPU都会更高.

Q21: ****DistributedDataParallel进行多机多卡训练的优缺点****

- **通信更快**: 相比于DP, 通信速度更快
- **负载相对均衡**: 相比于DP, GPU负载相对更均衡
- **运行速度快**: 因为通信时间更短, 效率更高, 能更快速的完成训练任务
