# CV

- Q1 **CV中, 语义分割和实例分割有什么区别?**

    - **语义分割**是一种检测每个像素所属的对象类别的技术.模型必须知道所有对象类别(标签).
    - **实例分割**类似于语义分割, 但更深入一些.它为每个像素标识它所属的对象实例.主要区别在于与语义分割相比, 区分具有相同标签的两个对象, 如下图: 

    ![https://i.stack.imgur.com/MEB9F.png](https://i.stack.imgur.com/MEB9F.png)

    - 在应用**语义分割**的第二张图片中, 类别(椅子)是输出之一, 所有椅子的颜色都相同.
    - 在第三张图片中, **实例分割**更进一步, 除了在第一步中识别类别(椅子)之外, 还将实例(椅子)彼此分开.

- Q2 **如何评估目标检测模型的好坏?**

    - 可以使用(`Intersection over Union`, `IoU`)评估指标, IoU用于衡量对象检测器在特定数据集上的准确性. 任何提供预测边界框作为输出的算法都可以使用`IoU`进行评估.`R-CNN`, `Faster R-CNN`, `YOLO`是此类模型的例子.
    - 例如, 在下图中, 预测边界框用红色绘制, 而真实边界框用绿色绘制. 模型性能是这些边界框之间的`IOU`.

    ![Untitled](CV/Untitled.png)

- Q3 **讲述标准的计算机视觉处理系统的主要处理步骤**

    标准的`CV`处理流程为: 
    
    - 1 输入图像: 计算机接收来自成像设备(如相机)的视觉输入. 这通常被捕获为形成视频的图像或图像序列.
    - 2 预处理: 每个图像都经过一些预处理步骤, 其目的是标准化每个图像. 常见的预处理步骤包括调整图像大小, 模糊处理, 旋转, 更改其形状或将图像从一种颜色转换为另一种颜色. 只有将每张图片标准化, 你才能对它们进行比较, 并以同样的方式进一步分析它们.
    - 3 特征提取.特征可以帮助我们定义某些对象, 它们通常是关于对象形状或颜色的信息. 例如, 一些区分摩托车车轮, 前大灯, 挡泥板等形状的特征. 这个过程的输出是一个特征向量.
    - 4 最后, 这些特征被输入到一个深度学习模型中, 在这个例子中是一个分类模型.

    ![Untitled](CV/Untitled1.png)
    Standard CV problem handling process.

- Q4 **目标检测领域, 如何判断一个特征是好特征?**

    一个好的特征将帮助我们以各种可能出现的方式识别一个对象. 这些特征包括边缘, 斑点和区域.一个好的特征有如下性质: 
    
    **可重复检测**: 当给定同一场景的两张图像时, 检测器在两张图像中发现的大多数特征都是相同的.这些特征对观察条件和噪声的变化具有鲁棒性, 换句话说, 该特征在不同的尺度, 光照条件和视角下是一致的.
    
    **独特性**: 特征中心周围的邻域变化足以允许该特征与其他特征进行可靠的比较.
    
    **Localizable**: 该特征具有唯一的位置信息.观看条件的变化不会影响其位置.
    

- Q5 **`CNN`在图像处理上表现好的原因有哪些**

    - `CNN`具有**局部相关性**, 图像数据是存在局部相关性的, 具体来说, 图像是由一个个像素点组成, 每个像素点与其周围的像素点是有关联的, 如果把像素点打乱, 图片会完全变掉, 
    - `CNN`具有**空间不变性**, `CNN`浅层网络提取低层次的特征, 比如边缘, 曲线等, 随着网络深度加深, 低层次的特征经过组合组成高层次的特征, 并且能够保持特征的**空间不变性**.

    引用: [https://www.zhihu.com/question/41233373/answer/91113816](https://www.zhihu.com/question/41233373/answer/91113816)

- Q6 **`BatchNorm`层的具体计算及作用**

    - BatchNorm层的计算公式: 

        $$
        y=\gamma\cdot \frac{x-\mu }{\sqrt{\sigma ^2+\varepsilon }}+\beta 
        $$

    - BatchNorm的作用是使得每层的输入/输出分布更加稳定, 避免参数更新和网络层次变深大幅度影响数据分布.从而使模型训练更稳定
    - 参数 $\beta$, $\gamma$的作用: 保留网络各层在训练过程中的学习成果, 保证激活单元的非线性表达能力, 使批归一化模块具有复原初始输出分布能力.

- Q7 **目标检测里如何有效解决常见的前景少背景多的问题**

    - 采用Focal Loss或OHEM进行负样本挖掘, 加大Hard Example损失权重
    - 训练时只利用Ground Truth周边的Prior Boxes进行训练, 忽略其他背景区域, 只考虑困难背景区域

- Q8 **ROIPool和ROIAlign的区别, 以及ROIAlign的简单实现**

    - ROIPool存在两次量化误差, 首先是将候选框边界量化为整数点坐标值, 其次是将量化后的边界区域平均分割成 k x k 个单元, 对每一个单元的边界进行量化.ROIAlign通过双线性插值避免了量化操作, 保存了原始ROI的空间分布, 有效避免了误差的产生, 对于检测图片中大目标物体时, 两种方案的差别不大, 而如果是图片中有较多小目标物体需要检测, 则优先选择ROIAlign, 更精准一些

    - 引用: [https://github.com/donnyyou/cv-interview](https://github.com/donnyyou/cv-interview)

- Q9 **Batch Norm在训练和推理的时候有什么区别?**

    - 在训练时, 我们可以计算出batch的均值和方差, 迭代训练过程中, 均值和方差一直在发生变化.但是在推理时, 均值和方差是固定的, 对于均值来说直接计算所有batch u值的平均值, 对于标准偏差采用每个batch σB的无偏估计.

- Q10 **为什么Relu激活函数逐渐取代了sigmoid函数?它的优势在哪里?**

    - ReLU函数的形式非常简洁, `ReLU = max(0, x)`, 是由两段线性函数(大于0部分是线性的, 小于0部分也是线性的, 但是组合起来后却是非线性的)组成的非线性函数, 函数形式看似简单, 但ReLU的组合却可以逼近任何函数.
    - ReLU解决了sigmoid函数导致的**梯度消失**问题的, 对比这两个函数的图形可以看出: ReLU有单侧抑制, 即Relu会使一部分神经元的输出为0, 这样就造成了网络的稀疏性, 并且减少了参数的相互依存关系, 缓解了过拟合问题的发生.另外这也更符合生物神经元的特征.
    - ReLU的运算速度快

- Q11 **ReLU函数在0处不可导, 实际应用时如何解决这个问题?**

    - 实际应用时, 人为提供一个伪梯度, 例如定义Relu在0处的导数为0, 其实tensorflow在实现ReLU的时候也是定义ReLU在0处的导数为0的

    - 引用: [https://blog.csdn.net/ningyanggege/article/details/82493023](https://blog.csdn.net/ningyanggege/article/details/82493023)

Q12 **图像处理中加入Pooling层的目的, 以及Pooling层是如何反向传播的?**

- Pooling层的作用: **增加非线性, 保留主要的特征同时减少参数(降维, 效果类似PCA)和计算量, 防止过拟合, 提高模型泛化能力, invariance(不变性), 这种不变性包括translation, rotation, scale, 具体来讲pooling层允许图像进行微小的变化**
- average pooling在前向传播中, 就是把一个patch中的值取平均传递给下一层的一个像素.因此, **在反向传播中, 就是把某个像素的值平均分成 n 份分配给上一层**
- max pooling在前向传播中, 把一个patch中最大的值传递给下一层, 其他值会被舍弃掉.因此, **在反向传播中, 就是将当前梯度直接传递给前一层的某个像素, 而让同一个patch中的其他像素值为0**.

Q14 **卷积层的FLOPs和参数量**

- **FLOPs: floating point operations, 浮点计算量, 可以用来衡量算法/模型的复杂度**
- 考虑bias情况下, 卷积层的FLOPs: $(2C_{in}*k^2)*C_{out}HW$, 其中$C_{in}$, $C_{out}$为输入通道输出通道, k为卷积核大小, H, W为输入图像的长宽
- 卷积层的参数量: $(k^2*C_{int}+1)C_{out}$

Q15 **使用F1-Score评价模型性能好坏有哪些好处?**

- F1 score 综合考虑了精确率和召回率, 其结果更偏向于 Precision 和 Recall 中较小的那个, 即 Precision 和 Recall 中较小的那个对 F1 score 的结果取决定性作用, **很多应用场景中会选择使用 F1 score 调和平均值而不是算术平均值, 因为我们希望这个结果可以更好地反映模型的性能好坏, 而不是直接平均模糊化了 Precision 和 Recall 各自对模型的影响**

Q16 ***ROI Pooling 和 ROI Align 的区别是什么***

- 在区域建议网络 RPN 得到候选框 ROI 之后, 需要提取该 ROI 中的固定数目的特征(例如Faster R-CNN中的 7*7 )输入到后面的分类网络以及边界回归网络的全连接层中.Faster R-CNN中使用的方法是 ROI Pooling, 而对于像素位置精细度要求更高的 Mask R-CNN 对 ROI Pooling 进行改进, 变成 ROI Align.
- **ROI Pooling和ROIAlign最大的区别是: 前者使用了两次量化操作, 而后者并没有采用量化操作, 使用了双线性插值算法**

Q17 ***特征融合时, concat和add操作的区别是什么?***

- add 方式有以下特点: 做的是对应通道对应位置的值的相加, 通道数不变, 描述图像的特征个数不变, 但是每个特征下的信息却增加了.
- concat方式做的是通道的合并, 通道数变多了, 描述图像的特征个数变多, 但是每个特征下的信息却不变.

Q18 ***阐述深度可分离卷积***

- 深度可分离卷积将常规的卷积分成了两步执行, 可以大大减小模型的**计算量**和**参数量**
- 深度可分离卷积的过程分为两部分: **深度卷积**(depthwise convolution) 和 **逐点卷积**
(pointwise convolution), 
- 深度卷积意在保持输入 feature map 的通道数, 对 feature map 中的每个通道使用一个规格为$K$的卷积核进行卷积, 输入 feature map 有多少个通道就有多少个这样的卷积核, 深度卷积结束后得到的输出的通道数与输入的相等, 不同通道的卷积结果不相加
- 逐点卷积: 在上一步的基础上, 运用 1ｘ1 卷积进行逐点卷积, 这一步进行通道的变换.

Q19 ***计算深度可分离卷积的FLOPs***

- 深度可分离卷积分成两部分, 一部分是分通道卷积, 另一部分是1*1卷积, 第一部分计算量: $(2k^2 )HWC_{int}$, 第二部分计算量: $2C_{int}HWC_{out}$

Q20 ***简述LBP算法原理***

- LBP是一种局部特征描述算子, 最原始的LBP算子使用大小为3×3的窗口, 将窗口中心邻域的8个像素分别与窗口中心像素其进行比较, 邻域像素值大于中心像素值的位置标记为1, 否则标记为0, 从而得到一个8位的二进制值, 将该值作为该窗口中心像素的LBP值(通常将8位的二进制值转换成十进制表示, 即有256种可能的LBP值).
- LBP算子具有旋转不变性, 纹理特征维度低, 计算速度快

Q21 ***简述HOG算法原理***

- HOG(方向梯度直方图), 通过计算和统计图像局部区域的梯度方向直方图来构建特征, 
- HOG算法先将图像划分为若干个cell, 然后计算各个cell中每个像素点的梯度和边缘方向, 然后分别统计每个cell的方向梯度直方图, 构成了每个cell的特征描述子, 为了对光照和阴影有更好的不变性, 需要对直方图进行对比度归一化, 具体可以通过将局部直方图在图像更大的范围内(称为block)进行对比度归一化.组合每个block中归一化后的所有cell的descriptor, 就构成了该block的descriptor.最后将所有block的descriptor组合起来就是整幅图像的HOG特征描述子.

Q22 **边缘检测算子有哪些以及它们之间的对比**

- 有许多方法用于边缘检测, 它们的绝大部分可以划分为两类: 基于查找一类和基于零穿越的一类.以及第三种, canny算子.
- 基于查找的方法通过寻找图像一阶导数中的最大和最小值来检测边界, 通常是将边界定位在梯度最大的方向, 如Roberts算子, **Prewitt 算子, Sobel 算子, **
- 基于零穿越的方法通过寻找图像二阶导数零穿越来寻找边界, 通常是Laplacian过零点或者非线性差分表示的过零点

Q23: ***常见的图像插值方式***

- 最近邻插值, 在待求像素的四邻域中, 将距离待求像素最近的邻像素的灰度值赋给待求像素
- 双线性插值: 利用待求像素四个相邻像素的灰度在两个方向上做线性插值, 也就是做两次线性变换
- 三次内插法: 利用三次多项式求逼近理论上的最佳插值函数, 待求像素 (x,y)
 的灰度值由其周围 16 个灰度值加权内插得到

 

Q24: ***FAST算法的原理***

- FAST算法是一种角点检测算法, 主要考虑像素点邻域的圆形窗口上的16个像素.如下图所示, 作者认为, 以像素 p 为中心的周围圆环上的16个像素中, 如果有连续 n 个像素点的灰度值都比 p 点的灰度值大或都小, 则认为 p 是一个角点.

![Untitled](CV%20interview%20Q&A%203d839484cf574c1899fd9f404a3b698d/Untitled%202.png)

- FAST角点检测速度快, 但受噪声影响大, 没有尺度不变性和旋转不变性

Q25: **简述BRIEF算法原理**

- BRIEF算法的主要思想是, 在特征点邻域的 s×s 窗口内随机选取 n 个点对, 通过比较这些点对来生成一个二进制串作为该特征点的特征描述子, 
- 具体的算法步骤是: 
    - 先对整幅图像提取特征点
    - 为了减少噪声影响, 对图像进行高斯滤波(因为BRIEF随机选取点对, 对噪声比较敏感)
    - 对于某个特征点, 在其 s×s 的邻域内随机选取一个点对, 比较两个点的大小: $T(x,y)=\begin{cases} 1, \quad if\ p(x)<p(y)\\ 0. \quad otherwise\end{cases}$ 其中, p(x), p(y)分别为随机点对(x,y)的灰度值
    - 重复第3步 n 次, 将 n 次比较的结果组合一个二进制串作为该特征点的特征描述子.一般 n 取128, 256或512

Q26: ***简述ORB算法原理***

- ORB算法使用FAST算法进行特征检测, 然后使用BRIEF算法来进行特征描述, ORB主要解决了BRIEF描述子不具备旋转不变性的问题, 具体的做法是: 提出了灰度质心法, 即计算特征点邻域内所有像素的灰度质心, 而通过特征点与质心就可以得到一个向量, 将这个向量作为特征点的方向, 当图像发生旋转时, 通过计算主方向旋转的角度就可以得到图像的旋转变换信息, 从而实现旋转不变性.

![Untitled](CV/Untitled3.png)

Q27: **简述SIFT特征, SIFT特征和SURF特征有什么区别?**

- SIFT特征是一种检测局部特征的算法, 其对**旋转, 尺度缩放, 亮度变化**保持不变性, 对**视角变化, 仿射变换, 噪声**也保持一定程度的稳定性, 
- SIFT算法的实质是在不同的尺度空间上查找关键点(特征点), 并计算出关键点的方向.分为以下四步: **尺度空间极值检测, 关键点定位, 方向确定, 关键点描述**
- surf是在sift的基础上改进而生, 不仅提高了计算速度, 而且更加安全鲁棒性, 具体的差异如下: 

|  | SIFT | SURF |
| --- | --- | --- |
| 尺度空间 | DOG与不同尺度的图片卷积 | 不同尺度的box filters与原图片卷积 |
| 特征点检测 | 先进行非极大抑制, 再去除低对比度的点.再通过Hessian矩阵去除边缘的点 | 先利用Hessian矩阵确定候选点, 然后进行非极大抑制 |
| 方向 | 在正方形区域内统计梯度的幅值的直方图, 找max对应的方向.可以有多个方向. | 在圆形区域内, 计算各个扇形范围内x, y方向的haar小波响应, 找模最大的扇形方向 |
| 特征描述子 | 16*16的采样点划分为4*4的区域, 计算每个区域的采样点的梯度方向和幅值, 统计成8bin直方图, 一共4*4*8=128维 | 2020s的区域划分为44的子区域, 每个子区域找55个采样点, 计算采样点的haar小波响应, 记录∑dx, ∑dy, ∑|dx|,∑|dy|, 一共44*4=64维 |

引用: [Sift与Surf的区别_eternity1118_的博客-CSDN博客_surf和sift区别](https://blog.csdn.net/eternity1118_/article/details/51152162)

Q28: **你了解哪些图像语义分割任务的loss?**

- ****cross entropy loss(交叉熵损失), 像素级别的交叉熵损失, ****这种损失会逐个检查每个像素, 将对每个像素类别的预测结果(概率分布向量)与one-hot标签向量进行比较, 每个像素的损失函数为: 

$$
pixel\ \ loss = -\sum_{classes}^{}y_{true}log(y_{pred})
$$

       整个图像的损失是对每个像素的损失求平均值

- ****weighted loss: 对输出概率分布向量中的每个值进行加权, 即希望模型更加关注数量较少的样本, 以缓解图像中存在的类别不均衡问题****
- **focal loss**: 是对标准交叉熵准则的改进, 随着正确类的置信度增加, 交叉熵损失与比例因子在零处衰减.比例因子在训练时自动降低简单数据的权重, 并**专注于困难数据**的训练
- Dice loss: 通过计算平滑骰子系数函数获得
- IOU loss: 增加高IoU样本的梯度, 降低低IoU样本的梯度

引用: [图像分割: 架构, 损失, 数据集和框架 - neptune.ai](https://neptune.ai/blog/image-segmentation)

Q29: **在边缘检测任务中, 比较Sobel算子和Canny算子**

- Sobel 运算符的主要优点是简单且更省时.但是, 检测边缘很粗糙.相比下, 由于Canny算法实现了非极大值抑制和双阈值技术, Canny 技术会产生更平滑的边缘.Canny算法的缺点是它比Sobel更复杂, 时间效率更低.

引用: [Microsoft Word - p107.doc (utm.my)](https://engineering.utm.my/comp/wp-content/uploads/sites/2/2013/04/Comparison-of-Canny-and-Sobel-Edge-Detection-in-MRI-Images.pdf)

Q30: **为什么图像在输入网络前要对图像做归一化?**

- **消除特征之间量纲的影响**, 使得不同特征之间具有可比性
- 在使用随机梯度下降求解的模型中, **能加快模型收敛速度**
- **归一化还有可能提高精度**: 一些分类器需要计算样本之间的距离(如欧氏距离), 例如KNN.如果一个特征值域范围非常大, 那么距离计算就主要取决于这个特征, 从而与实际情况相悖(比如这时实际情况是值域范围小的特征更重要).

Q31: ***在使用Yolo网络做目标检测时, 可能会碰到什么问题?***

- YOLO的每个网格都被限制为只能检测单个对象.因此, YOLO很难检测和定位自然成群的小物体, 例如一排蚂蚁, 
- YOLO 对照明或其他环境条件的变化很敏感, 因此在照明条件可能变化的实际应用中, 不适宜使用YOLO
- YOLO网络会消耗较多的计算资源, 使得边缘端部署较为困难

引用: [YOLO Algorithm for Object Detection Explained [+Examples] (v7labs.com)](https://www.v7labs.com/blog/yolo-object-detection)
